{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from tqdm.notebook import tqdm # Progession bar\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = os.path.abspath('../src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 33 \n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "data_dir = os.path.join('..', 'data')\n",
    "metadata_dir = os.path.join(data_dir, 'metadata')\n",
    "train_val_path = os.path.join(metadata_dir, 'train_val_list.txt')\n",
    "test_path = os.path.join(metadata_dir, 'test_list.txt')\n",
    "train_val = pd.read_csv(train_val_path,header=None,names=['Image Index'])\n",
    "test = pd.read_csv(test_path,header=None,names=['Image Index'])\n",
    "\n",
    "train, val= train_test_split(train_val, test_size=0.2, random_state=42)\n",
    "train_size= len(train)\n",
    "val_size = len(val)\n",
    "train_path = os.path.join(metadata_dir, 'train_list.txt')\n",
    "val_path = os.path.join(metadata_dir, 'val_list.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "metadata_file = os.path.join(metadata_dir, 'Data_Entry_2017_v2020.csv')\n",
    "metadata_df = pd.read_csv(metadata_file) \n",
    "metadata_df = metadata_df[metadata_df['Finding Labels'] !='No Finding']\n",
    "\n",
    "metadata_df['Finding Labels'] = metadata_df['Finding Labels'].str.split('|')\n",
    "\n",
    "# Aplicar el one-hot encoding\n",
    "mlb = MultiLabelBinarizer()\n",
    "one_hot = mlb.fit_transform(metadata_df['Finding Labels'])\n",
    "\n",
    "# Convertir a DataFrame y agregarlo a `metadata_df`\n",
    "one_hot_df = pd.DataFrame(one_hot, columns=mlb.classes_, index=metadata_df.index)\n",
    "metadata_df = pd.concat([metadata_df, one_hot_df], axis=1)\n",
    "\n",
    "\n",
    "val_df = pd.merge(metadata_df,val, how='inner')\n",
    "train_df = pd.merge(metadata_df,train, how='inner')\n",
    "test_df = pd.merge(metadata_df,test, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = os.path.join(data_dir,'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "dataloaders, dataset_sizes, class_counts = make_data_loaders(train_df, \n",
    "                                                                val_df,\n",
    "                                                                test_df, \n",
    "                                                                images_dir, \n",
    "                                                                32, \n",
    "                                                                224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "from torchvision.models import ResNet50_Weights\n",
    "model = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(num_ftrs, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.array(class_counts)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  \n",
    "criterion = get_loss('bce_w', counts, device)\n",
    "optimizer = get_optimizer(model.parameters(), optimizer='Adam', lr=1e-4, weight_decay=1e-5)\n",
    "scheduler = get_scheduler(optimizer, name='cyclic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MEDHYCON\\Documents\\Marta\\TFM\\ChestX-ray8_classification\\src\\train.py:161: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from epoch 2.\n",
      "Starting epoch 3/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 899/899 [03:32<00:00,  4.22it/s]\n",
      "Validating: 100%|██████████| 228/228 [02:14<00:00,  1.69it/s]\n",
      "c:\\Users\\MEDHYCON\\anaconda3\\envs\\tfm_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/12], Validation Loss: 0.1048, AUC: 0.5062, Precision: 0.0000, Recall: 0.0000, F1-score: 0.0000, Training Time: 212.81s, Validation Time: 134.58s, Total Time: 347.39s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Model checkpoint saved at epoch 3.\n",
      "Starting epoch 4/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 899/899 [03:31<00:00,  4.25it/s]\n",
      "Validating: 100%|██████████| 228/228 [02:16<00:00,  1.67it/s]\n",
      "c:\\Users\\MEDHYCON\\anaconda3\\envs\\tfm_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/12], Validation Loss: 0.0392, AUC: 0.5784, Precision: 0.0000, Recall: 0.0000, F1-score: 0.0000, Training Time: 211.30s, Validation Time: 136.32s, Total Time: 347.62s\n",
      "Model checkpoint saved at epoch 4.\n",
      "Starting epoch 5/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 899/899 [03:27<00:00,  4.33it/s]\n",
      "Validating: 100%|██████████| 228/228 [02:14<00:00,  1.69it/s]\n",
      "c:\\Users\\MEDHYCON\\anaconda3\\envs\\tfm_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/12], Validation Loss: 0.0395, AUC: 0.5755, Precision: 0.0000, Recall: 0.0000, F1-score: 0.0000, Training Time: 207.71s, Validation Time: 134.72s, Total Time: 342.44s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Model checkpoint saved at epoch 5.\n",
      "Starting epoch 6/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 899/899 [03:25<00:00,  4.37it/s]\n",
      "Validating: 100%|██████████| 228/228 [02:12<00:00,  1.72it/s]\n",
      "c:\\Users\\MEDHYCON\\anaconda3\\envs\\tfm_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/12], Validation Loss: 0.0391, AUC: 0.5862, Precision: 0.0000, Recall: 0.0000, F1-score: 0.0000, Training Time: 205.65s, Validation Time: 132.75s, Total Time: 338.40s\n",
      "Model checkpoint saved at epoch 6.\n",
      "Starting epoch 7/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 899/899 [03:25<00:00,  4.38it/s]\n",
      "Validating: 100%|██████████| 228/228 [02:16<00:00,  1.66it/s]\n",
      "c:\\Users\\MEDHYCON\\anaconda3\\envs\\tfm_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/12], Validation Loss: 0.0390, AUC: 0.5916, Precision: 0.0000, Recall: 0.0000, F1-score: 0.0000, Training Time: 205.03s, Validation Time: 137.00s, Total Time: 342.03s\n",
      "Model checkpoint saved at epoch 7.\n",
      "Starting epoch 8/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 899/899 [03:25<00:00,  4.38it/s]\n",
      "Validating: 100%|██████████| 228/228 [02:15<00:00,  1.68it/s]\n",
      "c:\\Users\\MEDHYCON\\anaconda3\\envs\\tfm_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/12], Validation Loss: 0.0390, AUC: 0.5890, Precision: 0.0000, Recall: 0.0000, F1-score: 0.0000, Training Time: 205.04s, Validation Time: 135.98s, Total Time: 341.02s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Model checkpoint saved at epoch 8.\n",
      "Starting epoch 9/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 899/899 [03:21<00:00,  4.47it/s]\n",
      "Validating: 100%|██████████| 228/228 [02:11<00:00,  1.73it/s]\n",
      "c:\\Users\\MEDHYCON\\anaconda3\\envs\\tfm_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/12], Validation Loss: 0.0391, AUC: 0.5966, Precision: 0.0000, Recall: 0.0000, F1-score: 0.0000, Training Time: 201.31s, Validation Time: 131.99s, Total Time: 333.30s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Model checkpoint saved at epoch 9.\n",
      "Starting epoch 10/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|███████▊  | 704/899 [02:35<00:43,  4.53it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m patience \u001b[39m=\u001b[39m \u001b[39m15\u001b[39m\n\u001b[0;32m      7\u001b[0m model_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m..\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m model \u001b[39m=\u001b[39m train_model(device, \n\u001b[0;32m      9\u001b[0m                     model, \n\u001b[0;32m     10\u001b[0m                     model_dir,\n\u001b[0;32m     11\u001b[0m                     dataloaders[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m], \n\u001b[0;32m     12\u001b[0m                     dataloaders[\u001b[39m'\u001b[39;49m\u001b[39mval\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m     13\u001b[0m                     criterion,\n\u001b[0;32m     14\u001b[0m                     optimizer,\n\u001b[0;32m     15\u001b[0m                     scheduler,\n\u001b[0;32m     16\u001b[0m                     num_epochs,\n\u001b[0;32m     17\u001b[0m                     steps,\n\u001b[0;32m     18\u001b[0m                     s_patience,\n\u001b[0;32m     19\u001b[0m                     patience)\n",
      "File \u001b[1;32mc:\\Users\\MEDHYCON\\Documents\\Marta\\TFM\\ChestX-ray8_classification\\src\\train.py:32\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(device, model, model_dir, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, steps, s_patience, patience)\u001b[0m\n\u001b[0;32m     29\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \n\u001b[0;32m     31\u001b[0m \u001b[39mfor\u001b[39;00m i, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tqdm(train_loader, desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining\u001b[39m\u001b[39m\"\u001b[39m)):\n\u001b[1;32m---> 32\u001b[0m     \u001b[39mif\u001b[39;00m steps \u001b[39mand\u001b[39;00m (i \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m steps):\n\u001b[0;32m     33\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     images \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from train import *\n",
    "num_epochs = 10\n",
    "steps = None\n",
    "s_patience = 3\n",
    "patience = 15\n",
    "\n",
    "model_dir = os.path.join('..','models')\n",
    "model = train_model(device, \n",
    "                    model, \n",
    "                    model_dir,\n",
    "                    dataloaders['train'], \n",
    "                    dataloaders['val'],\n",
    "                    criterion,\n",
    "                    optimizer,\n",
    "                    scheduler,\n",
    "                    num_epochs,\n",
    "                    steps,\n",
    "                    s_patience,\n",
    "                    patience)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
