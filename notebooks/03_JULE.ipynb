{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JULE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from tqdm.notebook import tqdm # Progession bar\n",
    "from PIL import Image\n",
    "import torchvision.models as models\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetos y rutas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "src_path = os.path.abspath('../src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "data_dir = os.path.join('..', 'data')\n",
    "metadata_dir = os.path.join(data_dir, 'metadata')\n",
    "test_csv = os.path.join(metadata_dir, 'test_metadata.csv')\n",
    "train_csv = os.path.join(metadata_dir, 'train_metadata.csv')\n",
    "val_csv = os.path.join(metadata_dir, 'val_metadata.csv')\n",
    "\n",
    "images_dir = os.path.join(data_dir,'images')\n",
    "processed_dir = os.path.join(data_dir,'processed')\n",
    "model_dir = os.path.join('..','models','jule')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_loaders_unsupervised(train_csv, val_csv, test_csv,processed_dir, images_dir, batch_size, image_size):\n",
    "    from torch.utils.data import DataLoader, Dataset\n",
    "    from PIL import Image\n",
    "\n",
    "    class ImageDataset(Dataset):\n",
    "        def __init__(self, csv_file, root_dir, transform=None):\n",
    "            self.data = pd.read_csv(csv_file)\n",
    "            self.root_dir = root_dir\n",
    "            self.transform = transform\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.data)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            img_name = os.path.join(self.root_dir, self.data.iloc[idx, 0])\n",
    "            image = Image.open(img_name).convert('RGB')\n",
    "\n",
    "            # Obtener las etiquetas (asumiendo que empiezan desde el segundo índice)\n",
    "            labels = self.data.iloc[idx, 1:].values.astype(np.float32)\n",
    "\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "\n",
    "            return image, labels\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    train_dataset = ImageDataset(train_csv, processed_dir, transform)\n",
    "    val_dataset = ImageDataset(val_csv, images_dir, transform)\n",
    "    test_dataset = ImageDataset(test_csv, images_dir, transform)\n",
    "\n",
    "    dataloaders = {\n",
    "        'train': DataLoader(train_dataset, batch_size=batch_size, shuffle=True),\n",
    "        'val': DataLoader(val_dataset, batch_size=batch_size, shuffle=False),\n",
    "        'test': DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    }\n",
    "    return dataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = make_data_loaders_unsupervised(train_csv,val_csv,test_csv,processed_dir,images_dir,33,224)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ResNet50Encoder(nn.Module):\n",
    "    def __init__(self, embedding_dim=128):\n",
    "        super(ResNet50Encoder, self).__init__()\n",
    "        resnet = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "        self.features = nn.Sequential(*list(resnet.children())[:-1]) \n",
    "        self.fc = nn.Linear(resnet.fc.in_features, embedding_dim)  \n",
    "        self.normalize = nn.functional.normalize  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return self.normalize(x, p=2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ResNet50Encoder().to(device)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de pérdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelTripletLoss(nn.Module):\n",
    "    def __init__(self, margin=0.2):\n",
    "        super(MultiLabelTripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        pos_dist = torch.sum((anchor - positive) ** 2, dim=1)\n",
    "        neg_dist = torch.sum((anchor - negative) ** 2, dim=1)\n",
    "        loss = torch.relu(pos_dist - neg_dist + self.margin)\n",
    "        return torch.mean(loss)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicClusterer:\n",
    "    def __init__(self, n_clusters, linkage='average'):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.linkage = linkage\n",
    "\n",
    "    def fit_predict(self, embeddings):\n",
    "        # Calculate cosine similarity matrix instead of Euclidean distance\n",
    "        similarity_matrix = cosine_similarity(embeddings)\n",
    "        # Convert similarity to distance (1 - similarity)\n",
    "        distance_matrix = 1 - similarity_matrix\n",
    "        # Perform hierarchical clustering\n",
    "        clustering_model = AgglomerativeClustering(\n",
    "            n_clusters=self.n_clusters, metric='precomputed', linkage=self.linkage\n",
    "        )\n",
    "        cluster_labels = clustering_model.fit_predict(distance_matrix)\n",
    "        return cluster_labels\n",
    "def perform_clustering_dynamic(embeddings, n_clusters=14):\n",
    "    clusterer = DynamicClusterer(n_clusters=n_clusters)\n",
    "    return clusterer.fit_predict(embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_unsupervised(model, dataloader, optimizer, criterion, device, num_epochs=10, n_clusters=14):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        all_embeddings = []\n",
    "        for imgs, _ in dataloader:\n",
    "            imgs = imgs.to(device)\n",
    "            embeddings = model(imgs)\n",
    "            all_embeddings.append(embeddings.detach().cpu().numpy())\n",
    "\n",
    "        all_embeddings = np.vstack(all_embeddings)\n",
    "        cluster_labels = perform_clustering_dynamic(all_embeddings, n_clusters=n_clusters)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        print(f\"Cluster distribution: {np.bincount(cluster_labels)}\")\n",
    "\n",
    "        # Update triplets and train\n",
    "        for imgs,_ in dataloader:\n",
    "            imgs = imgs.to(device)\n",
    "            embeddings = model(imgs)\n",
    "            batch_size = embeddings.size(0)\n",
    "            divisible_batch_size = (batch_size // 3) * 3\n",
    "            if divisible_batch_size < 3:\n",
    "                continue  # Saltar lotes demasiado pequeños\n",
    "\n",
    "            embeddings = embeddings[:divisible_batch_size]  # Truncar a divisible por 3\n",
    "            anchor, positive, negative = torch.chunk(embeddings, 3)\n",
    "           \n",
    "            loss = criterion(anchor, positive, negative)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        torch.save(model.state_dict(), f\"model_{n_clusters}_epoch_{epoch + 1}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MEDHYCON\\anaconda3\\envs\\tfm_env\\lib\\site-packages\\sklearn\\cluster\\_agglomerative.py:1006: FutureWarning: Attribute `affinity` was deprecated in version 1.2 and will be removed in 1.4. Use `metric` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = MultiLabelTripletLoss()\n",
    "dataloader = dataloaders['train']\n",
    "train_model_unsupervised(model, dataloader, optimizer, criterion, device, num_epochs=5, n_clusters=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_nmi(dataloader, model, device, n_clusters=14):\n",
    "    # Step 1: Generate embeddings\n",
    "    embeddings, true_labels = load_model_and_generate_embeddings(dataloader, model, device)\n",
    "\n",
    "    # Step 2: Perform clustering on embeddings\n",
    "    cluster_labels = perform_clustering(embeddings, n_clusters=n_clusters)\n",
    "\n",
    "    # Step 3: Compute NMI\n",
    "    nmi_score = normalized_mutual_info_score(true_labels, cluster_labels)\n",
    "    print(f\"NMI Score: {nmi_score:.4f}\")\n",
    "    return nmi_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_nmi(dataloader['test'],model,device,n_clusters=14)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
