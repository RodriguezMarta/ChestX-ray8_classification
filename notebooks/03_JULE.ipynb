{
 "cells": [
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA"
=======
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JULE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from tqdm.notebook import tqdm # Progession bar\n",
    "from PIL import Image\n",
    "import torchvision.models as models\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetos y rutas"
>>>>>>> ccb95274d036e7bfa85134793feb89b0ffa52a5c
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
=======
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "src_path = os.path.abspath('../src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "data_dir = os.path.join('..', 'data')\n",
    "metadata_dir = os.path.join(data_dir, 'metadata')\n",
    "test_csv = os.path.join(metadata_dir, 'test_metadata.csv')\n",
    "train_csv = os.path.join(metadata_dir, 'train_metadata.csv')\n",
    "val_csv = os.path.join(metadata_dir, 'val_metadata.csv')\n",
    "\n",
    "images_dir = os.path.join(data_dir,'images')\n",
    "processed_dir = os.path.join(data_dir,'processed')\n",
    "model_dir = os.path.join('..','models','jule')"
>>>>>>> ccb95274d036e7bfa85134793feb89b0ffa52a5c
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_loaders(train_csv, val_csv, test_csv, images_dir, batch_size, image_size):\n",
=======
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_loaders_unsupervised(train_csv, val_csv, test_csv,processed_dir, images_dir, batch_size, image_size):\n",
>>>>>>> ccb95274d036e7bfa85134793feb89b0ffa52a5c
    "    from torch.utils.data import DataLoader, Dataset\n",
    "    from PIL import Image\n",
    "\n",
    "    class ImageDataset(Dataset):\n",
    "        def __init__(self, csv_file, root_dir, transform=None):\n",
    "            self.data = pd.read_csv(csv_file)\n",
    "            self.root_dir = root_dir\n",
    "            self.transform = transform\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.data)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            img_name = os.path.join(self.root_dir, self.data.iloc[idx, 0])\n",
    "            image = Image.open(img_name).convert('RGB')\n",
<<<<<<< HEAD
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image\n",
=======
    "\n",
    "            # Obtener las etiquetas (asumiendo que empiezan desde el segundo índice)\n",
    "            labels = self.data.iloc[idx, 1:].values.astype(np.float32)\n",
    "\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "\n",
    "            return image, labels\n",
>>>>>>> ccb95274d036e7bfa85134793feb89b0ffa52a5c
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
<<<<<<< HEAD
    "    train_dataset = ImageDataset(train_csv, images_dir, transform)\n",
=======
    "    train_dataset = ImageDataset(train_csv, processed_dir, transform)\n",
>>>>>>> ccb95274d036e7bfa85134793feb89b0ffa52a5c
    "    val_dataset = ImageDataset(val_csv, images_dir, transform)\n",
    "    test_dataset = ImageDataset(test_csv, images_dir, transform)\n",
    "\n",
    "    dataloaders = {\n",
    "        'train': DataLoader(train_dataset, batch_size=batch_size, shuffle=True),\n",
    "        'val': DataLoader(val_dataset, batch_size=batch_size, shuffle=False),\n",
    "        'test': DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    }\n",
<<<<<<< HEAD
    "    return dataloaders\n",
    "\n",
    "# Define the ResNet50 model with a custom embedding layer\n",
    "class ResNet50Encoder(nn.Module):\n",
    "    def __init__(self, embedding_dim=128):\n",
    "        super(ResNet50Encoder, self).__init__()\n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "        self.features = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        self.fc = nn.Linear(resnet.fc.in_features, embedding_dim)\n",
    "        self.normalize = nn.functional.normalize\n",
=======
    "    return dataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = make_data_loaders_unsupervised(train_csv,val_csv,test_csv,processed_dir,images_dir,33,224)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ResNet50Encoder(nn.Module):\n",
    "    def __init__(self, embedding_dim=128):\n",
    "        super(ResNet50Encoder, self).__init__()\n",
    "        resnet = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "        self.features = nn.Sequential(*list(resnet.children())[:-1]) \n",
    "        self.fc = nn.Linear(resnet.fc.in_features, embedding_dim)  \n",
    "        self.normalize = nn.functional.normalize  \n",
>>>>>>> ccb95274d036e7bfa85134793feb89b0ffa52a5c
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
<<<<<<< HEAD
    "        return self.normalize(x, p=2, dim=1)\n",
    "\n",
    "# Define the MultiLabelTripletLoss\n",
=======
    "        return self.normalize(x, p=2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ResNet50Encoder().to(device)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de pérdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
>>>>>>> ccb95274d036e7bfa85134793feb89b0ffa52a5c
    "class MultiLabelTripletLoss(nn.Module):\n",
    "    def __init__(self, margin=0.2):\n",
    "        super(MultiLabelTripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        pos_dist = torch.sum((anchor - positive) ** 2, dim=1)\n",
    "        neg_dist = torch.sum((anchor - negative) ** 2, dim=1)\n",
    "        loss = torch.relu(pos_dist - neg_dist + self.margin)\n",
    "        return torch.mean(loss)\n",
<<<<<<< HEAD
    "\n",
    "# Clustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "def perform_clustering(embeddings, n_clusters=14):\n",
    "    clustering_model = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')\n",
    "    cluster_labels = clustering_model.fit_predict(embeddings)\n",
    "    return cluster_labels\n",
    "\n",
    "# Training function\n",
=======
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicClusterer:\n",
    "    def __init__(self, n_clusters, linkage='average'):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.linkage = linkage\n",
    "\n",
    "    def fit_predict(self, embeddings):\n",
    "        # Calculate cosine similarity matrix instead of Euclidean distance\n",
    "        similarity_matrix = cosine_similarity(embeddings)\n",
    "        # Convert similarity to distance (1 - similarity)\n",
    "        distance_matrix = 1 - similarity_matrix\n",
    "        # Perform hierarchical clustering\n",
    "        clustering_model = AgglomerativeClustering(\n",
    "            n_clusters=self.n_clusters, metric='precomputed', linkage=self.linkage\n",
    "        )\n",
    "        cluster_labels = clustering_model.fit_predict(distance_matrix)\n",
    "        return cluster_labels\n",
    "def perform_clustering_dynamic(embeddings, n_clusters=14):\n",
    "    clusterer = DynamicClusterer(n_clusters=n_clusters)\n",
    "    return clusterer.fit_predict(embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
>>>>>>> ccb95274d036e7bfa85134793feb89b0ffa52a5c
    "def train_model_unsupervised(model, dataloader, optimizer, criterion, device, num_epochs=10, n_clusters=14):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        all_embeddings = []\n",
<<<<<<< HEAD
    "        for imgs in dataloader:\n",
=======
    "        for imgs, _ in dataloader:\n",
>>>>>>> ccb95274d036e7bfa85134793feb89b0ffa52a5c
    "            imgs = imgs.to(device)\n",
    "            embeddings = model(imgs)\n",
    "            all_embeddings.append(embeddings.detach().cpu().numpy())\n",
    "\n",
    "        all_embeddings = np.vstack(all_embeddings)\n",
<<<<<<< HEAD
    "        embeddings_np = all_embeddings.detach().cpu().numpy()\n",
    "        pca = PCA(n_components=50)  # Reduce a 50 dimensiones\n",
    "        reduced_embeddings = pca.fit_transform(embeddings_np)\n",
    "        \n",
    "        #cluster_labels = clustering_model.fit_predict(embeddings_np,n_clusters)\n",
    "        cluster_labels = perform_clustering(reduced_embeddings, n_clusters=n_clusters)\n",
=======
    "        cluster_labels = perform_clustering_dynamic(all_embeddings, n_clusters=n_clusters)\n",
>>>>>>> ccb95274d036e7bfa85134793feb89b0ffa52a5c
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        print(f\"Cluster distribution: {np.bincount(cluster_labels)}\")\n",
    "\n",
    "        # Update triplets and train\n",
<<<<<<< HEAD
    "        for imgs in dataloader:\n",
    "            imgs = imgs.to(device)\n",
    "            embeddings = model(imgs)\n",
    "            # Here you would create triplets based on cluster_labels\n",
    "            # For simplicity, assume we have anchor, positive, negative:\n",
    "            anchor, positive, negative = embeddings[0], embeddings[1], embeddings[2]\n",
=======
    "        for imgs,_ in dataloader:\n",
    "            imgs = imgs.to(device)\n",
    "            embeddings = model(imgs)\n",
    "            batch_size = embeddings.size(0)\n",
    "            divisible_batch_size = (batch_size // 3) * 3\n",
    "            if divisible_batch_size < 3:\n",
    "                continue  # Saltar lotes demasiado pequeños\n",
    "\n",
    "            embeddings = embeddings[:divisible_batch_size]  # Truncar a divisible por 3\n",
    "            anchor, positive, negative = torch.chunk(embeddings, 3)\n",
    "           \n",
>>>>>>> ccb95274d036e7bfa85134793feb89b0ffa52a5c
    "            loss = criterion(anchor, positive, negative)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
<<<<<<< HEAD
    "        torch.save(model.state_dict(), f\"model_epoch_{epoch + 1}.pth\")"
=======
    "        torch.save(model.state_dict(), f\"model_{n_clusters}_epoch_{epoch + 1}.pth\")"
>>>>>>> ccb95274d036e7bfa85134793feb89b0ffa52a5c
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 22,
>>>>>>> ccb95274d036e7bfa85134793feb89b0ffa52a5c
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "c:\\Users\\RSCBAL04\\anaconda3\\envs\\marta_env\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\RSCBAL04\\anaconda3\\envs\\marta_env\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[0;32m     16\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m dataloaders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 17\u001b[0m \u001b[43mtrain_model_unsupervised\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m14\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 85\u001b[0m, in \u001b[0;36mtrain_model_unsupervised\u001b[1;34m(model, dataloader, optimizer, criterion, device, num_epochs, n_clusters)\u001b[0m\n\u001b[0;32m     83\u001b[0m all_embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack(all_embeddings)\n\u001b[0;32m     84\u001b[0m pca \u001b[38;5;241m=\u001b[39m PCA(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)  \u001b[38;5;66;03m# Reduce a 50 dimensiones\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m reduced_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mpca\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m embeddings_np \u001b[38;5;241m=\u001b[39m reduced_embeddings\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     87\u001b[0m cluster_labels \u001b[38;5;241m=\u001b[39m clustering_model\u001b[38;5;241m.\u001b[39mfit_predict(embeddings_np,n_clusters)\n",
      "File \u001b[1;32mc:\\Users\\RSCBAL04\\anaconda3\\envs\\marta_env\\lib\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\RSCBAL04\\anaconda3\\envs\\marta_env\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\RSCBAL04\\anaconda3\\envs\\marta_env\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:460\u001b[0m, in \u001b[0;36mPCA.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    439\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \n\u001b[0;32m    441\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;124;03m    C-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 460\u001b[0m     U, S, Vt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    461\u001b[0m     U \u001b[38;5;241m=\u001b[39m U[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components_]\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwhiten:\n\u001b[0;32m    464\u001b[0m         \u001b[38;5;66;03m# X_new = X * V / S * sqrt(n_samples) = U * sqrt(n_samples)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\RSCBAL04\\anaconda3\\envs\\marta_env\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:483\u001b[0m, in \u001b[0;36mPCA._fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    479\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPCA does not support sparse input. See \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    480\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTruncatedSVD for a possible alternative.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    481\u001b[0m     )\n\u001b[1;32m--> 483\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# Handle n_components==None\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\RSCBAL04\\anaconda3\\envs\\marta_env\\lib\\site-packages\\sklearn\\base.py:605\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    603\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 605\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    607\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\RSCBAL04\\anaconda3\\envs\\marta_env\\lib\\site-packages\\sklearn\\utils\\validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    913\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 915\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    917\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    918\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    919\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\RSCBAL04\\anaconda3\\envs\\marta_env\\lib\\site-packages\\sklearn\\utils\\_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    378\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 380\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[1;32mc:\\Users\\RSCBAL04\\anaconda3\\envs\\marta_env\\lib\\site-packages\\torch\\_tensor.py:1085\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m   1084\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
=======
      "c:\\Users\\MEDHYCON\\anaconda3\\envs\\tfm_env\\lib\\site-packages\\sklearn\\cluster\\_agglomerative.py:1006: FutureWarning: Attribute `affinity` was deprecated in version 1.2 and will be removed in 1.4. Use `metric` instead\n",
      "  warnings.warn(\n"
>>>>>>> ccb95274d036e7bfa85134793feb89b0ffa52a5c
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "train_csv = \"C:/Users/RSCBAL04/Documents/GitHub/ChestX-ray8_classification/data/metadata/train.csv\"\n",
    "val_csv = \"C:/Users/RSCBAL04/Documents/GitHub/ChestX-ray8_classification/data/metadata/train.csv\"\n",
    "test_csv = \"C:/Users/RSCBAL04/Documents/GitHub/ChestX-ray8_classification/data/metadata/train.csv\"\n",
    "images_dir = \"C:/Users/RSCBAL04/Documents/GitHub/ChestX-ray8_classification/data/images\"\n",
    "dataloaders = make_data_loaders(train_csv, val_csv, test_csv, images_dir, batch_size=32, image_size=224)\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Model and optimizer setup\n",
    "model = ResNet50Encoder().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = MultiLabelTripletLoss()\n",
    "\n",
    "# Train\n",
    "dataloader = dataloaders['train']\n",
    "train_model_unsupervised(model, dataloader, optimizer, criterion, device, num_epochs=10, n_clusters=14)\n"
=======
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = MultiLabelTripletLoss()\n",
    "dataloader = dataloaders['train']\n",
    "train_model_unsupervised(model, dataloader, optimizer, criterion, device, num_epochs=5, n_clusters=18)"
>>>>>>> ccb95274d036e7bfa85134793feb89b0ffa52a5c
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
<<<<<<< HEAD
   "display_name": "marta_env",
=======
   "display_name": "tfm_env",
>>>>>>> ccb95274d036e7bfa85134793feb89b0ffa52a5c
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.8.20"
  }
=======
   "version": "3.8.12"
  },
  "orig_nbformat": 4
>>>>>>> ccb95274d036e7bfa85134793feb89b0ffa52a5c
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
